# Explainable AI

## Introduction

Explainable artificial intelligence (XAI) is a set of processes and methods that allows human users to comprehend and trust the results and output created by machine learning algorithms. Explainable AI is used to describe an AI model, its expected impact and potential biases. It helps characterize model accuracy, fairness, transparency and outcomes in AI-powered decision making. Explainable AI is crucial for an organization in building trust and confidence when putting AI models into production. AI explainability also helps an organization adopt a responsible approach to AI development.

 
 ## Pretrained models which used by XAI algorithms

### VGG variations 

A convolutional neural network with n layers (we used 16 or 19) is called VGG-nn. The ImageNet database contains a pretrained version of the network that has been trained on more than a million pictures (check [ImageNet](https://image-net.org/)). The pretrained network can categorize photos into 1000 different item categories, including several animals, a keyboard, a mouse, and a pencil. The network has therefore acquired rich feature representations for a variety of pictures. The network usually accepts images with a resolution of 224 by 224.

### RandomForest

Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Could work for both classification and regression problems. Each individual tree in the random forest spits out either a continues value or a class prediction and the class with the most votes becomes our modelâ€™s prediction.